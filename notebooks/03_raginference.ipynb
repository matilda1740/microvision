{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630fa8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd() == '/Users/matildamwendwa/Desktop/Desktop - Adminâ€™s MacBook Pro/Python_Projects/microvision/notebooks':\n",
    "    os.chdir('/Users/matildamwendwa/Desktop/Desktop - Adminâ€™s MacBook Pro/Python_Projects/microvision')\n",
    "    print(\"Changed!!\")\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ded96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb sentence-transformers tqdm pandas numpy matplotlib networkx  faiss --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ee727",
   "metadata": {},
   "source": [
    "#### SETTING UP THE ENVIRONMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import embedding\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------ CONFIGURATIONS -----\n",
    "config = {\n",
    "        \"DATA_DIR\": \"data\",\n",
    "        \"DATASET_NAME\": \"OpenStack\",\n",
    "        \"DATASET_LOG\": \"_full.log\",\n",
    "        \"ENRICHED_CSV\": \"_enriched.csv\",\n",
    "        \"TEMPLATES_CSV\": \"_templates.csv\",\n",
    "        \"TEMPLATES_JSON\": \"_templates.json\",\n",
    "        \"MAX_LINES\": None,  # Set to None to process all lines\n",
    "        \"PERSISTENCE_PATH\": \"persistence\",\n",
    "        \"DRAIN_PATH\": \"drain3_state\",\n",
    "                \n",
    "        \"EMBEDDINGS_CSV\": \"_embeddings.csv\",\n",
    "        \"CHROMA_PERSIST_DIR\": \"chroma_storage\",\n",
    "        \"COLLECTION_NAME\": \"_collection\"\n",
    "}\n",
    "\n",
    "os.makedirs(config[\"DATA_DIR\"], exist_ok=True)\n",
    "\n",
    "# ------ LOADING EMBEDDINGS DATAFRAME -----\n",
    "embeddings_csv_path = f\"{config['DATA_DIR']}/{config['DATASET_NAME']}{config['DATASET_LOG']}{config['EMBEDDINGS_CSV']}\"\n",
    "embeddings_df = pd.read_csv(embeddings_csv_path)\n",
    "embeddings_df[\"embedding\"] = embeddings_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\",\"))\n",
    "print(f\"âœ… Loaded embeddings DataFrame with {len(embeddings_df)} rows from {embeddings_csv_path}\")\n",
    "\n",
    "# ------ CONNECTING TO CHROMADB -----\n",
    "\n",
    "chroma_persist_dir = f\"{config['DATA_DIR']}/{config['PERSISTENCE_PATH']}/{config['CHROMA_PERSIST_DIR']}\"\n",
    "client = chromadb.PersistentClient(path=chroma_persist_dir)\n",
    "print(f\"âœ… Connected to ChromaDB client, {chroma_persist_dir}\")\n",
    "\n",
    "collection_name = f\"{config['DATASET_NAME']}{config['DATASET_LOG']}{config['COLLECTION_NAME']}\"\n",
    "# print(f\"Chroma contains collections: {client.list_collections()}\")\n",
    "\n",
    "collection = client.get_collection(collection_name)\n",
    "print(f\"ðŸ“¦ Active collection: {collection.name}, embeddings: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817adee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ LOADING THE SENTENCE TRANSFORMER MODEL -----\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "print(f\"âœ… Model Loaded: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56b88f5",
   "metadata": {},
   "source": [
    "#### UTILITY FUNCTIONS USED IN THE RAG ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- QUICK VERIFICATION OF EMEDDINGS\n",
    "\n",
    "def ensure_unique_ids(df, id_col):\n",
    "    \"\"\"\n",
    "    Ensure unique identifiers for all templates (string IDs).\n",
    "    Converts duplicates into distinct suffixed IDs.\n",
    "    \"\"\"\n",
    "    tqdm.write(\"ðŸ”¢ Ensuring unique template IDs...\")\n",
    "    seen = {}\n",
    "    new_ids = []\n",
    "    for val in df[id_col].astype(str):\n",
    "        count = seen.get(val, 0)\n",
    "        if count > 0:\n",
    "            new_ids.append(f\"{val}_{count}\")\n",
    "        else:\n",
    "            new_ids.append(val)\n",
    "        seen[val] = count + 1\n",
    "    df[id_col] = new_ids\n",
    "    return df\n",
    "\n",
    "def validate_embeddings_shape(df, col):\n",
    "    \"\"\"\n",
    "    Validate and convert stored embeddings into numpy arrays.\n",
    "    \"\"\"\n",
    "    tqdm.write(\"ðŸ§© Validating embedding structures...\")\n",
    "    return np.vstack(df[col].apply(lambda e: np.array(e, dtype=float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a46d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating the embeddings dataframe\n",
    "embeddings_df = ensure_unique_ids(embeddings_df, id_col=\"template_id\")\n",
    "embeddings_array = validate_embeddings_shape(embeddings_df, col=\"embedding\")\n",
    "print(f\"âœ… Embeddings shape: {embeddings_array.shape}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa950ef6",
   "metadata": {},
   "source": [
    "#### Retrieval Module Functions\n",
    "\n",
    "Using ChromaDB's Internal ANN retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_retrieve_topk(collection, query_embeddings, top_k, metadata_filter, include_distances):\n",
    "    # tqdm.write(f\"ðŸ” Retrieving top-{top_k} neighbors from Chroma (filters={metadata_filter})\")\n",
    "\n",
    "    query_embeddings = np.atleast_2d(query_embeddings).tolist()\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embeddings,\n",
    "        n_results=top_k,\n",
    "        where=metadata_filter if isinstance(metadata_filter, dict) else None\n",
    "    )\n",
    "\n",
    "    output = []\n",
    "    for i, _ in enumerate(query_embeddings):\n",
    "        batch = {\n",
    "            \"ids\": results[\"ids\"][i],\n",
    "            \"documents\": results[\"documents\"][i],\n",
    "            \"metadatas\": results[\"metadatas\"][i],\n",
    "        }\n",
    "        if include_distances and \"distances\" in results:\n",
    "            batch[\"distances\"] = results[\"distances\"][i]\n",
    "        output.append(batch)\n",
    "    \n",
    "    # print(\"Retrieved Output: \", output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c735c91d",
   "metadata": {},
   "source": [
    "#### Post-Retrieval Functions\n",
    "\n",
    "1. Metadata Correlation Scoring\n",
    "\n",
    "\n",
    "2. Temporal Validation Function: it validates the causal direction between two services based on timestamps. \n",
    "\n",
    "if: ts_a precedes ts_b within window the it returns \"A->B\"\n",
    "elif: ts_b precedes ts_a within window the it returns \"B->A\"\n",
    "else: none\n",
    "\n",
    "3. Semantic and Metadata Similarity Score Functions\n",
    "\n",
    "3.1 Score Normalization Function: Normalizes list/array of scores into [0, 1]\n",
    "\n",
    "3.2 Fusion Function: Fuses semantic and metadata similarity scores into a hybrid score, also has a parameter alpha\n",
    "that represents the weight for semantic similarity (0â€“1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- METADATA SCORING FUNCTIONS --------\n",
    "\n",
    "import ast\n",
    "\n",
    "def normalize_metadata(meta):\n",
    "    \"\"\"Normalize metadata dict for case-insensitive matching and parsing.\"\"\"\n",
    "    if isinstance(meta, str):\n",
    "        try:\n",
    "            meta = ast.literal_eval(meta)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    if not isinstance(meta, dict):\n",
    "        # Handles Pandas Series (row) or other structures\n",
    "        if hasattr(meta, \"to_dict\"):\n",
    "            meta = meta.to_dict()\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    # Convert all keys to lowercase and string values\n",
    "    return {str(k).lower(): str(v).strip() for k, v in meta.items()}\n",
    "\n",
    "def compute_metadata_weights(df, fields):\n",
    "    weights = {f: 1 / max(df[f].nunique(), 1) for f in fields}\n",
    "    total = sum(weights.values())\n",
    "    weights = {k: v / total for k, v in weights.items()}\n",
    "    tqdm.write(f\"âš–ï¸ Metadata weights: {weights}\")\n",
    "    return weights\n",
    "\n",
    "\n",
    "def metadata_correlation_score(src_meta, target_meta, fields, weights):\n",
    "    src = {k.lower(): str(v).strip() for k, v in src_meta.items()}\n",
    "    target = {k.lower(): str(v).strip() for k, v in target_meta.items()}\n",
    "\n",
    "    score, total = 0.0, 0.0\n",
    "    for f in fields:\n",
    "        f_lower = f.lower()\n",
    "        total += weights.get(f, 0)\n",
    "        if src.get(f_lower) and src.get(f_lower) == target.get(f_lower):\n",
    "            score += weights.get(f, 0)\n",
    "    return score / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b4494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_timestamp(row):\n",
    "    date, time = row.get(\"date\"), row.get(\"time\")\n",
    "    if pd.notna(date) and pd.notna(time):\n",
    "        try:\n",
    "            return pd.to_datetime(f\"{date} {time}\", errors=\"coerce\")\n",
    "        except Exception:\n",
    "            return pd.NaT\n",
    "    return pd.NaT\n",
    "\n",
    "# -------- TEMPORAL DIRECTION VALIDATION FUNCTION --------\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "def parse_ts(ts):\n",
    "    if isinstance(ts, (datetime, pd.Timestamp)):\n",
    "        return ts\n",
    "    try:\n",
    "        return pd.to_datetime(str(ts), errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "        \n",
    "def temporal_direction(ts_a, ts_b, max_window):\n",
    "    # Debug info\n",
    "    # print(f\"ts_a: {ts_a}, ts_b: {ts_b}\")\n",
    "\n",
    "    # Handle missing or invalid timestamps\n",
    "    # if pd.isna(ts_a) or pd.isna(ts_b):\n",
    "    #     return \"none\", None\n",
    "\n",
    "    # Safe parsing function\n",
    "\n",
    "\n",
    "    ts_a = parse_ts(ts_a)\n",
    "    ts_b = parse_ts(ts_b)\n",
    "\n",
    "    # Ensure both are valid\n",
    "    # if pd.isna(ts_a) or pd.isna(ts_b):\n",
    "    #     return \"none\", None\n",
    "\n",
    "    # Compute delta in seconds\n",
    "    delta = (ts_b - ts_a).total_seconds()\n",
    "\n",
    "\n",
    "    if 0 < delta <= max_window:\n",
    "        direction = \"Aâ†’B\"\n",
    "    elif -max_window <= delta < 0:\n",
    "        direction = \"Bâ†’A\"\n",
    "    else:\n",
    "        direction = \"none\"\n",
    "    \n",
    "    return direction, abs(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safe_normalize(series):\n",
    "    \"\"\"Normalize safely to [0,1], handling constants or NaNs.\"\"\"\n",
    "    if series.nunique() <= 1 or series.isna().all():\n",
    "        return pd.Series(np.full(len(series), 0.5), index=series.index)\n",
    "    scaler = MinMaxScaler()\n",
    "    return pd.Series(scaler.fit_transform(series.values.reshape(-1, 1)).flatten(), index=series.index)\n",
    "\n",
    "\n",
    "def postprocess_scores(df, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Normalize semantic + metadata scores AFTER building dataframe.\n",
    "    Compute hybrid score globally across all candidates.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Normalize globally (not per row)\n",
    "    df[\"semantic_distance_norm\"] = safe_normalize(df[\"semantic_distance\"])\n",
    "    df[\"metadata_score_norm\"] = safe_normalize(df[\"metadata_score\"])\n",
    "\n",
    "    # Convert distance â†’ similarity (invert scale)\n",
    "    df[\"semantic_similarity\"] = 1 - df[\"semantic_distance_norm\"]\n",
    "\n",
    "    # Weighted hybrid fusion\n",
    "    df[\"hybrid_score\"] = (\n",
    "        alpha * df[\"semantic_similarity\"] + (1 - alpha) * df[\"metadata_score_norm\"]\n",
    "    ).round(4)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccba00",
   "metadata": {},
   "source": [
    "##### Building Candidate Dependencies\n",
    "\n",
    "Constructs dependency candidates using Chromaâ€™s retriever and post-retrieval scoring. \n",
    "\n",
    "The function has the following parameters: \n",
    "df : the embeddings dataframe\n",
    "collection: persistent chroma collection containing vectors\n",
    "top_k: number of semantic neighbors to retrieve\n",
    "meta_fields: metadata fields to use for correlation\n",
    "alpha: weight for semantics vs metadata score fusion\n",
    "max_time_window: temporal validation window in seconds\n",
    "\n",
    "and returns the output:\n",
    "candidates_df: candidate dependency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13df2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_candidates(df, collection, top_k, meta_fields, alpha, max_time_window):\n",
    "\n",
    "    meta_fields = meta_fields\n",
    "    weights = compute_metadata_weights(df, meta_fields)\n",
    "\n",
    "    candidates = []\n",
    "    tqdm.write(\"ðŸš€ Building hybrid dependency candidates via Chroma retriever...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Evaluating templates\"):\n",
    "        query_emb = np.array(row[\"embedding\"], dtype=float)\n",
    "\n",
    "        # NORMALIZING THE CASE (UPPER/LOWER) OF THE METADATA\n",
    "        src_meta = normalize_metadata(row)\n",
    "        results = semantic_retrieve_topk(collection, query_emb, top_k=top_k, metadata_filter=meta_fields   , include_distances=True)\n",
    "        retrieved = results[0]\n",
    "\n",
    "        # Loop through each retrieved match\n",
    "        for j, doc_id in enumerate(retrieved[\"ids\"]):\n",
    "            # SKIP SELF-MATCHES\n",
    "            if (\n",
    "                doc_id == row[\"embedding_id\"]\n",
    "                or doc_id == row[\"template_id\"]\n",
    "                or row[\"template_id\"] in row[\"embedding_id\"]\n",
    "                or row[\"embedding_id\"].endswith(row[\"template_id\"])\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            target_meta = normalize_metadata(retrieved[\"metadatas\"][j])\n",
    "            semantic_dist = retrieved[\"distances\"][j] if \"distances\" in retrieved else np.nan\n",
    "            meta_score = metadata_correlation_score(src_meta, target_meta, meta_fields, weights)\n",
    "\n",
    "            timestamp = safe_timestamp(target_meta)\n",
    "            direction, delta = temporal_direction(row.get(\"Timestamp\"), timestamp, max_time_window)\n",
    "            relation_type = (\n",
    "                \"self-edge\" if src_meta.get(\"component\") == target_meta.get(\"component\") else \"inter_service\"\n",
    "            )\n",
    "\n",
    "            # print(\"Source Component:\", src_meta)\n",
    "            # print(\"Target Componet:\", target_meta)\n",
    "\n",
    "            candidates.append({\n",
    "                \"src_id\": row[\"template_id\"],\n",
    "                \"target_id\": doc_id,\n",
    "                \"src_component\": src_meta.get(\"component\"),\n",
    "                \"target_component\": target_meta.get(\"component\"),\n",
    "                \"relation_type\": relation_type,\n",
    "                \"semantic_distance\": float(semantic_dist),\n",
    "                \"metadata_score\": meta_score,\n",
    "                \"temporal_relation\": direction,\n",
    "                \"time_diff_seconds\": delta,\n",
    "            })\n",
    "    \n",
    "    candidates_df = pd.DataFrame(candidates)\n",
    "    tqdm.write(f\"âœ… Built {len(candidates_df)} candidates.\")\n",
    "    return candidates_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df = infer_candidates(\n",
    "    embeddings_df,\n",
    "    collection=collection,\n",
    "    top_k=5,\n",
    "    meta_fields=[\"Pid\", \"Component\", \"Level\"],\n",
    "    alpha=0.7,   # weight for semantic importance\n",
    "    max_time_window=5.0\n",
    ")\n",
    "candidates_df = postprocess_scores(candidates_df, alpha=0.7)\n",
    "inferred_df = candidates_df[candidates_df[\"relation_type\"] == \"inter_service\"]\n",
    "# âœ… Inspect\n",
    "print(\"ðŸ§© Inter-Service Candidate Dependencies built:\", len(inferred_df))\n",
    "display(inferred_df.sort_values(\"hybrid_score\", ascending=False).head(len(inferred_df)))\n",
    "# print(inferred_df.info())\n",
    "# print(inferred_df[\"semantic_distance\"].describe())\n",
    "# print(inferred_df[\"metadata_score\"].describe())\n",
    "# print(inferred_df[\"metadata_score\"].describe())\n",
    "# print(inferred_df[\"metadata_score\"].value_counts().head(10))\n",
    "# print(inferred_df[\"relation_type\"].value_counts())\n",
    "# print(inferred_df[\"relation_type\"].unique())  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b0072",
   "metadata": {},
   "source": [
    "#### Inferred Candidate Dependency Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9fcaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges with score attributes\n",
    "for _, row in inferred_df.iterrows():\n",
    "    G.add_edge(row[\"src_component\"], row[\"target_component\"], weight=row[\"hybrid_score\"])\n",
    "\n",
    "# Layout & edge color mapping\n",
    "pos = nx.spring_layout(G, seed=42, k=0.7)\n",
    "weights = np.array([d[\"weight\"] for _, _, d in G.edges(data=True)])\n",
    "norm = plt.Normalize(vmin=weights.min(), vmax=weights.max())\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "# Create figure and explicit axes so colorbar can be attached to the same axes\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    G, pos, ax=ax,\n",
    "    node_size=800, node_color=\"lightgray\", edgecolors=\"blue\"\n",
    ")\n",
    "edges = nx.draw_networkx_edges(\n",
    "    G, pos, ax=ax,\n",
    "    edge_color=weights,\n",
    "    edge_cmap=cmap,\n",
    "    edge_vmin=weights.min(),\n",
    "    edge_vmax=weights.max(),\n",
    "    arrows=True,\n",
    "    arrowsize=12\n",
    ")\n",
    "nx.draw_networkx_labels(G, pos, ax=ax, font_size=9, font_weight=\"bold\", font_color=\"red\")\n",
    "\n",
    "# Add colorbar properly linked to the same axes\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array(weights)  # associate actual values\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Hybrid Score\")\n",
    "\n",
    "ax.set_title(\"Inferred Inter-Service Dependency Graph\")\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
